{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sNHGT2FjjZiK",
        "Eb_cbyoaHKrT",
        "a9JW1rhH3H-T"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install InsightFace and Dependencies:**\n",
        "\n",
        "\n",
        "\n",
        " Run the following code to install the required packages.\n",
        "\n",
        "\n",
        "\n",
        " Note: This installation varies and depends on your cuda and cudnn version. Incase of face swapping issue refer to the link in the debug session to know the version to install."
      ],
      "metadata": {
        "id": "U3Fc3OXuDeqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install onnx==1.16.0\n",
        "!pip install onnxruntime-gpu==1.18.0 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "!pip install insightface #==0.7.3\n",
        "#!pip install onnxruntime==1.18.0\n",
        "!apt-get install -y ffmpeg\n",
        "!ffmpeg -version\n",
        "!mkdir deepfakecollab"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D-UgHjSFBE9d",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9767ca0f-93d2-4d3b-d097-79138a18f0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
            "Collecting onnxruntime-gpu==1.18.0\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/onnxruntime-gpu/1.18/onnxruntime_gpu-1.18.0-cp311-cp311-manylinux_2_28_x86_64.whl (200.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime-gpu==1.18.0)\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/coloredlogs/15.0.1/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu==1.18.0)\n",
            "  Downloading https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/9387c3aa-d9ad-4513-968c-383f6f7f53b8/pypi/download/humanfriendly/10/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu==1.18.0) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.18.0\n",
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.6)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.11.4)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface) (5.29.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.4.26)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1064776 sha256=67aa767fac9bc8859c187d713157396d8cfe6d01bd9fd286fc722b73ceb7b3e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, insightface\n",
            "Successfully installed insightface-0.7.3 onnx-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DeepFakeLive\n",
        "\n",
        "Follow the steps below to create the necessery directories for the project"
      ],
      "metadata": {
        "id": "GYFbuuCdvTaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd deepfakecollab\n",
        "!mkdir deepfakecollab/Scripts"
      ],
      "metadata": {
        "id": "lJJbUDokN0bF"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional] FRP\n",
        "\n",
        "\n",
        "\n",
        "Follow the steps below to setup FRP. You will also need to host the FRPS on your VPS (free).\n",
        "\n",
        "\n",
        "\n",
        "Note: You cannot run both FRP and ngrok together. Its ether FRP and ngrok"
      ],
      "metadata": {
        "id": "0rTCd2R1uw7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch deepfakecollab/Scripts/get_frs.sh\n",
        "getfrs = \"\"\"#!/usr/bin/env bash\n",
        "# Check if frpc is installed\n",
        "command -v frpc >/dev/null 2>&1\n",
        "if [[ $? -ne 0 ]]; then\n",
        "    echo \"frpc is not found, installing...\"\n",
        "    wget -q -nc https://github.com/fatedier/frp/releases/download/v0.59.0/frp_0.59.0_linux_amd64.tar.gz\n",
        "    tar -xzf frp_0.59.0_linux_amd64.tar.gz\n",
        "    echo \"Done!\"\n",
        "fi\"\"\"\n",
        "with open('deepfakecollab/Scripts/get_frs.sh', 'w') as f:\n",
        "    f.write(getfrs)\n",
        "!touch deepfakecollab/Scripts/open_tunnel_frs.sh\n",
        "getfrs = \"\"\"#!/usr/bin/env bash\n",
        "cmd=\"frp_0.59.0_linux_amd64/frpc -c frp_0.59.0_linux_amd64/frpc.toml\"\n",
        "kill -9 $(ps aux | grep $cmd | awk '{print $2}') 2> /dev/null\n",
        "echo Opening tunnel\n",
        "$cmd\"\"\"\n",
        "with open('deepfakecollab/Scripts/open_tunnel_frs.sh', 'w') as f:\n",
        "    f.write(getfrs)\n",
        "!chmod +x deepfakecollab/Scripts/get_frs.sh\n",
        "!chmod +x deepfakecollab/Scripts/open_tunnel_frs.sh\n",
        "!deepfakecollab/Scripts/get_frs.sh"
      ],
      "metadata": {
        "id": "ckp_dM52N9K3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T16:35:36.013401Z",
          "iopub.execute_input": "2024-11-11T16:35:36.013863Z",
          "iopub.status.idle": "2024-11-11T16:35:37.835343Z",
          "shell.execute_reply.started": "2024-11-11T16:35:36.013814Z",
          "shell.execute_reply": "2024-11-11T16:35:37.833430Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5c6a4a1f-95e5-4923-a64b-fabd5a33911a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frpc is not found, installing...\n",
            "Done!\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional]  Ngrok\n",
        "\n",
        "\n",
        "\n",
        "Follow to Setup Ngrok.\n",
        "\n",
        "\n",
        "\n",
        "Note: You need an API key from Ngrok to use tcp for free you would need to add a billing details to their platform"
      ],
      "metadata": {
        "id": "9n-qESinvM22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch deepfakecollab/Scripts/get_ngrok.sh\n",
        "getfrs = \"\"\"#!/usr/bin/env bash\n",
        "# Check if frpc is installed\n",
        "command -v frpc >/dev/null 2>&1\n",
        "if [[ $? -ne 0 ]]; then\n",
        "    echo \"ngrok is not found, installing...\"\n",
        "    wget -q -nc https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "    tar -xzf ngrok-v3-stable-linux-amd64.tgz\n",
        "    echo \"Done!\"\n",
        "fi\"\"\"\n",
        "with open('deepfakecollab/Scripts/get_ngrok.sh', 'w') as f:\n",
        "    f.write(getfrs)\n",
        "!touch deepfakecollab/Scripts/open_tunnel_ngrok.sh\n",
        "getfrs = \"\"\"#!/usr/bin/env bash\n",
        "cmd=\"./ngrok start --all --config ngrok.conf\"\n",
        "kill -9 $(ps aux | grep $cmd | awk '{print $2}') 2> /dev/null\n",
        "echo Opening tunnel\n",
        "$cmd\"\"\"\n",
        "with open('deepfakecollab/Scripts/open_tunnel_ngrok.sh', 'w') as f:\n",
        "    f.write(getfrs)\n",
        "!chmod +x deepfakecollab/Scripts/get_ngrok.sh\n",
        "!chmod +x deepfakecollab/Scripts/open_tunnel_ngrok.sh\n",
        "!deepfakecollab/Scripts/get_ngrok.sh"
      ],
      "metadata": {
        "id": "S9U6x85DvTTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62db32f-4fb0-4092-e146-855f847c92a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok is not found, installing...\n",
            "Done!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set your region\n",
        "\n",
        "\n",
        "\n",
        "Code | Region\n",
        "\n",
        "--- | ---\n",
        "\n",
        "us | United States\n",
        "\n",
        "eu | Europe\n",
        "\n",
        "ap | Asia/Pacific\n",
        "\n",
        "au | Australia\n",
        "\n",
        "sa | South America\n",
        "\n",
        "jp | Japan\n",
        "\n",
        "in | India"
      ],
      "metadata": {
        "id": "uVpDmuTmwtO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your region here in quotes\n",
        "# Paste your authtoken here in quotes\n",
        "authtoken = \"7HKfxNqQ2Nqj1CBaj7Edz_38czuFxKRg7kcc28rgUVK\"\n",
        "region = \"ap\""
      ],
      "metadata": {
        "id": "MM-UUANCwwqo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model Folder\n",
        "\n",
        "\n",
        "\n",
        "Create and download into the model folder"
      ],
      "metadata": {
        "id": "JmNGrasvwnVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p deepfakecollab/Model\n",
        "!wget https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128_fp16.onnx -P /content/deepfakecollab/Model\n",
        "!wget https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth -P /content/deepfakecollab/Model"
      ],
      "metadata": {
        "id": "EU1ZXGlGw8Rb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fc6a5465-789e-4baa-9fa9-c413c09b399d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-06 06:30:39--  https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128_fp16.onnx\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-05-06 06:30:40 ERROR 404: Not Found.\n",
            "\n",
            "--2025-05-06 06:30:40--  https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.118, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/47/8e/478ea6841e7ee9b6a18fcbd35a172c66f44ae30fcce68054ea545317cb889208/e2cd4703ab14f4d01fd1383a8a8b266f9a5833dacee8e6a79d3bf21a1b6be5ad?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27GFPGANv1.4.pth%3B+filename%3D%22GFPGANv1.4.pth%22%3B&Expires=1746516640&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NjUxNjY0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Ny84ZS80NzhlYTY4NDFlN2VlOWI2YTE4ZmNiZDM1YTE3MmM2NmY0NGFlMzBmY2NlNjgwNTRlYTU0NTMxN2NiODg5MjA4L2UyY2Q0NzAzYWIxNGY0ZDAxZmQxMzgzYThhOGIyNjZmOWE1ODMzZGFjZWU4ZTZhNzlkM2JmMjFhMWI2YmU1YWQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=bgZ09Bjs7oUN-nrGgHqOrMEz0N5G6dXF9%7EKQCr4zBzKPWXE6b1KgK2H1O1fK3v9SqvoeH5CDMS6ItjdVMYDF1IlFYSIRpxvglgsUfkJYehv8WNUdWnW5%7EhvhR8b%7EVQR3NBo8nKgsxoqSwNSjLm%7EZC5K0qxxyzd-AWoXMEsO1bxezn8dFEWP3KBLb8-pxP01cu%7EmpqbQN9tMdC6fOopj9ETMOyJepYkEl3wE72f0evXPJHyw4WbmSD0dR5-bLR53R80qGOGoEVSw5PPmw42yRmOaTAQ1rsKe5sgT11SdBX%7EG0afrI7d92PjIizuR0y5c5ukwH6Ym%7EofAyNrMoWr9GYQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-06 06:30:40--  https://cdn-lfs.hf.co/repos/47/8e/478ea6841e7ee9b6a18fcbd35a172c66f44ae30fcce68054ea545317cb889208/e2cd4703ab14f4d01fd1383a8a8b266f9a5833dacee8e6a79d3bf21a1b6be5ad?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27GFPGANv1.4.pth%3B+filename%3D%22GFPGANv1.4.pth%22%3B&Expires=1746516640&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NjUxNjY0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80Ny84ZS80NzhlYTY4NDFlN2VlOWI2YTE4ZmNiZDM1YTE3MmM2NmY0NGFlMzBmY2NlNjgwNTRlYTU0NTMxN2NiODg5MjA4L2UyY2Q0NzAzYWIxNGY0ZDAxZmQxMzgzYThhOGIyNjZmOWE1ODMzZGFjZWU4ZTZhNzlkM2JmMjFhMWI2YmU1YWQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=bgZ09Bjs7oUN-nrGgHqOrMEz0N5G6dXF9%7EKQCr4zBzKPWXE6b1KgK2H1O1fK3v9SqvoeH5CDMS6ItjdVMYDF1IlFYSIRpxvglgsUfkJYehv8WNUdWnW5%7EhvhR8b%7EVQR3NBo8nKgsxoqSwNSjLm%7EZC5K0qxxyzd-AWoXMEsO1bxezn8dFEWP3KBLb8-pxP01cu%7EmpqbQN9tMdC6fOopj9ETMOyJepYkEl3wE72f0evXPJHyw4WbmSD0dR5-bLR53R80qGOGoEVSw5PPmw42yRmOaTAQ1rsKe5sgT11SdBX%7EG0afrI7d92PjIizuR0y5c5ukwH6Ym%7EofAyNrMoWr9GYQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.202.83, 18.155.202.101, 18.155.202.123, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.202.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 348632874 (332M) [binary/octet-stream]\n",
            "Saving to: ‘/content/deepfakecollab/Model/GFPGANv1.4.pth’\n",
            "\n",
            "GFPGANv1.4.pth      100%[===================>] 332.48M   214MB/s    in 1.6s    \n",
            "\n",
            "2025-05-06 06:30:42 (214 MB/s) - ‘/content/deepfakecollab/Model/GFPGANv1.4.pth’ saved [348632874/348632874]\n",
            "\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Ignore]  DeBuggin (Run only when its necessery)\n",
        "\n",
        "\n",
        "\n",
        "Debugging to ensure cuda was used. if not check the version of the cudnn, edit the install of the onnxruntime package to install the right version. https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements"
      ],
      "metadata": {
        "id": "sNHGT2FjjZiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQr-gWl6Ibw7",
        "outputId": "1f5478a4-a8e5-4031-ddf2-c70f11b3dda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#define CUDNN_MAJOR 8\n",
            "#define CUDNN_MINOR 9\n",
            "#define CUDNN_PATCHLEVEL 6\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "/* cannot use constexpr here since this is a C-only file */\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as rt\n",
        "print(rt.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ9r-s_9Kdha",
        "outputId": "40d6780a-fbbc-4a1b-a100-9651a73fd2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.18.0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the GPU providers are set explicitly\n",
        "ort_session = rt.InferenceSession(\n",
        "    \"/content/deepfakecollab/Model/inswapper_128_fp16.onnx\",\n",
        "    providers=[\"TensorrtExecutionProvider\", \"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
        ")\n",
        "# Verify the active provider again\n",
        "print(\"Active providers:\", ort_session.get_providers())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stwb4OHv_hs0",
        "outputId": "c4e8f6d6-4580-442a-d892-8a404065d484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:456 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(onnxruntime::python::PySessionOptions&, const ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "Active providers: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime import get_device\n",
        "print(\"ONNX Runtime is using:\", get_device())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk5osj-z2gST",
        "outputId": "53582ef7-de8d-45ee-d9fe-4a03d263f52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX Runtime is using: GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtkP4SLy7g9S",
        "outputId": "2e2b216c-04c9-497e-b429-de22b7a7e9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 15 08:42:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0              55W / 400W |    959MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Colab Server\n",
        "\n",
        "\n",
        "\n",
        "In your Google Colab notebook, set up a TCP server that will receive frames, process them using the FACE_SWAPPER model, and send back the results."
      ],
      "metadata": {
        "id": "DTbmyO-CK-8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n",
        "import cv2\n",
        "import numpy as np\n",
        "import insightface\n",
        "import threading\n",
        "import torch\n",
        "import onnxruntime\n",
        "from typing import Any\n",
        "from insightface.app.common import Face\n",
        "import matplotlib.pyplot as plt\n",
        "# Check if CUDA is available\n",
        "if 'CUDAExecutionProvider' in onnxruntime.get_available_providers():\n",
        "    providers = ['CUDAExecutionProvider']\n",
        "elif 'TensorrtExecutionProvider'  in onnxruntime.get_available_providers():\n",
        "    providers = ['TensorrtExecutionProvider']\n",
        "else:\n",
        "    providers = ['CPUExecutionProvider']\n",
        "print(providers)\n",
        "FACE_SWAPPER = None\n",
        "FACE_ANALYSER = insightface.app.FaceAnalysis(name='buffalo_l', providers=providers)\n",
        "FACE_ANALYSER.prepare(ctx_id=0, det_size=(640, 640))\n",
        "THREAD_LOCK = threading.Lock()\n",
        "Frame = np.ndarray[Any, Any]\n",
        "def get_face_swapper() -> Any:\n",
        "    global FACE_SWAPPER\n",
        "    with THREAD_LOCK:\n",
        "        if FACE_SWAPPER is None:\n",
        "            model_path = \"/content/deepfakecollab/Model/inswapper_128_fp16.onnx\"\n",
        "            FACE_SWAPPER = insightface.model_zoo.get_model(model_path, providers=['CUDAExecutionProvider'])\n",
        "    return FACE_SWAPPER\n",
        "def swap_face(source_face: Face, target_face: Face, temp_frame: Frame) -> Frame:\n",
        "    return get_face_swapper().get(temp_frame, target_face, source_face, paste_back=True)\n",
        "def get_face_analyser() -> Any:\n",
        "    #FACE_ANALYSER.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    return FACE_ANALYSER\n",
        "def get_one_face(frame: Frame) -> Any:\n",
        "    face = get_face_analyser().get(frame)\n",
        "    try:\n",
        "        return min(face, key=lambda x: x.bbox[0])\n",
        "    except ValueError:\n",
        "        return None\n",
        "def get_many_faces(frame: Frame) -> Any:\n",
        "    try:\n",
        "        return get_face_analyser().get(frame)\n",
        "    except IndexError:\n",
        "        return None\n",
        "def process_frame(source_face: Face, temp_frame: Frame,manyface: bool) -> Frame:\n",
        "    if manyface:\n",
        "        many_faces = get_many_faces(temp_frame)\n",
        "        if many_faces:\n",
        "            for target_face in many_faces:\n",
        "                temp_frame = swap_face(source_face, target_face, temp_frame)\n",
        "    else:\n",
        "        target_face = get_one_face(temp_frame)\n",
        "        if target_face:\n",
        "            temp_frame = swap_face(source_face, target_face, temp_frame)\n",
        "    return temp_frame\n",
        "# Input and output ports for communication\n",
        "local_in_source = 5555\n",
        "local_in_temp = 5556\n",
        "local_out_frame = 5557"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1661
        },
        "id": "P4xE5bpeosP_",
        "outputId": "eb14b925-1d63-4baf-98e5-1d17793781f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-6-1129645534ae>\", line 4, in <cell line: 0>\n",
            "    import insightface\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/insightface/__init__.py\", line 8, in <module>\n",
            "    import onnxruntime\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnxruntime/__init__.py\", line 23, in <module>\n",
            "    from onnxruntime.capi._pybind_state import ExecutionMode  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/_pybind_state.py\", line 32, in <module>\n",
            "    from .onnxruntime_pybind11_state import *  # noqa\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Unable to import dependency onnxruntime. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/insightface/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#import mxnet as mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimport_capi_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mimport_capi_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutionMode\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutionOrder\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/_pybind_state.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0monnxruntime_pybind11_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1129645534ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minsightface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/insightface/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"Unable to import dependency onnxruntime. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n",
            "\u001b[0;31mImportError\u001b[0m: Unable to import dependency onnxruntime. ",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional] For Live Streaming\n",
        "\n",
        "For Live Streaming from webcam run this cell but for just image swap run the next cell.\n",
        "\n",
        "\n",
        "\n",
        "Note: Don't run both cells at same time. You should either run this or the one below\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FehUyVNvGGgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zmq\n",
        "import threading\n",
        "import cv2\n",
        "import numpy as np\n",
        "import msgpack\n",
        "import queue\n",
        "import time\n",
        "import zlib\n",
        "from tqdm import tqdm\n",
        "import subprocess\n",
        "from collections import deque\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import deque\n",
        "\n",
        "# Initialize the executor with the number of workers\n",
        "executor = ThreadPoolExecutor(max_workers=4)  # Adjust based on your CPU cores\n",
        "# Batch size - tune this based on available resources and processing time per frame\n",
        "BATCH_SIZE = 120\n",
        "# Holds future results for parallel processing\n",
        "future_to_batch = {}\n",
        "#import matplotlib.pyplot as plt\n",
        "def create_demo_image():\n",
        "    # Create a demo image (e.g., a solid color or pattern)\n",
        "    demo_image = np.zeros((540, 960, 3), dtype=np.uint8)  # Black image\n",
        "    cv2.putText(demo_image, 'Demo Image', (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "    return demo_image\n",
        "def pull_socket(local_in_port):\n",
        "    context = zmq.Context()\n",
        "    socket = context.socket(zmq.REP)\n",
        "    socket.setsockopt(zmq.RCVHWM, 100000)\n",
        "    socket.setsockopt(zmq.LINGER, 0)\n",
        "    address = f\"tcp://127.0.0.1:{local_in_port}\"\n",
        "    socket.bind(address)  # Binding to a different local port\n",
        "    print(f\"PULL one socket bound to {address}\")\n",
        "    return socket\n",
        "# Compress image\n",
        "def compress_image(image, quality=95):\n",
        "    # Set the JPEG quality parameter\n",
        "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n",
        "    # Encode the image as a JPEG\n",
        "    result, encimg = cv2.imencode('.jpg', image, encode_param)\n",
        "    if not result:\n",
        "        raise Exception(\"Image encoding failed\")\n",
        "    # Decode the encoded image back to an image format\n",
        "    decimg = cv2.imdecode(encimg, 1)\n",
        "    return decimg\n",
        "# Decompress image\n",
        "def decompress_image(encimg):\n",
        "    image = cv2.imdecode(np.frombuffer(encimg, np.uint8), cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "# Global variables\n",
        "frames_array=deque(maxlen=2000)\n",
        "temp_frames_array=deque(maxlen=2000)\n",
        "source_frame = None\n",
        "is_manyFace = None\n",
        "frameSize = '960x540'\n",
        "fps = None\n",
        "# Process a batch of frames simultaneously\n",
        "# Function to process each frame\n",
        "def process_frame_parallel(source, frame, many_face):\n",
        "    return process_frame(get_one_face(source), frame, many_face)\n",
        "\n",
        "def pull_worker(pull_socket):\n",
        "    global source_frame,is_manyFace,frameSize,fps\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive the JSON with total chunks\n",
        "            meta_data_json = pull_socket.recv_json()\n",
        "            #print(meta_data_json)\n",
        "            total_chunk = meta_data_json['total_chunk']\n",
        "            # Send acknowledgment for metadata\n",
        "            pull_socket.send_string(\"ACK\")\n",
        "            # Receive the array bytes\n",
        "            source_array_bytes =b''\n",
        "            for i in range(total_chunk):\n",
        "                chunk = pull_socket.recv()\n",
        "                source_array_bytes += chunk\n",
        "                pull_socket.send_string(f\"ACK {i + 1}/{total_chunk}\")\n",
        "            end_message = pull_socket.recv()\n",
        "            if end_message == b\"END\":\n",
        "                pull_socket.send_string(\"Final ACK\")\n",
        "\n",
        "            # Deserialize the bytes back to an ndarray\n",
        "            source_array = np.frombuffer(source_array_bytes, dtype=np.dtype(meta_data_json['dtype_source'])).reshape(meta_data_json['shape_source'])\n",
        "            source_frame = source_array\n",
        "            is_manyFace = meta_data_json['manyface']\n",
        "            frameSize =  meta_data_json['size']\n",
        "            fps = meta_data_json[\"fps\"]\n",
        "                #process_queue.put((\"source\", source_array))\n",
        "            break\n",
        "        except zmq.Again:\n",
        "            # Sleep briefly to avoid busy-waiting\n",
        "            time.sleep(0.01)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "def pull_worker_two(local_in_temp):\n",
        "    ffmpeg_receive_command =  [\n",
        "        'ffmpeg',\n",
        "        '-i',f'tcp://127.0.0.1:{local_in_temp}?listen&fifo_size=100000&overrun_nonfatal=1',\n",
        "        '-f','rawvideo',\n",
        "        '-pix_fmt','bgr24',\n",
        "        '-s','960x540',\n",
        "        'pipe:1'\n",
        "    ]\n",
        "    ffmpeg_receive_process = subprocess.Popen((ffmpeg_receive_command), stdout=subprocess.PIPE)\n",
        "    timefame =1/25\n",
        "    print(f\"InputStream ffmpeg bound from tcp://127.0.0.1:{local_in_temp}?listen\")\n",
        "    global source_frame,is_manyFace\n",
        "    future_to_frame = {}\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive the JSON with total chunks\n",
        "            # Read decoded frame from FFmpeg\n",
        "            raw_frame = ffmpeg_receive_process.stdout.read(960 * 540 * 3)\n",
        "            if not raw_frame:\n",
        "                break\n",
        "            framex = np.frombuffer(raw_frame, dtype=np.uint8).reshape((540, 960, 3))\n",
        "            source_array = source_frame\n",
        "            is_many_face = is_manyFace\n",
        "            temp_frames_array.append(framex)\n",
        "            if source_frame is not None:\n",
        "                while len(temp_frames_array)>1:\n",
        "                    t_frames = temp_frames_array[-1]\n",
        "                    frames_array.append(t_frames)\n",
        "                    temp_frames_array.popleft()\n",
        "        except zmq.Again:\n",
        "            # Sleep briefly to avoid busy-waiting\n",
        "            time.sleep(0.01)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "def push_worker(local_out_frame):\n",
        "    source_array = None\n",
        "    temp_array = None\n",
        "    is_many_face = None\n",
        "    timefrate = 120\n",
        "    maxcount = 0\n",
        "    global source_frame,is_manyFace,frameSize,fps\n",
        "    print(f\"OutputStream ffmpeg bound to tcp://127.0.0.1:{local_out_frame}?listen\")\n",
        "    ffmpeg_encode_command = [\n",
        "        'ffmpeg',\n",
        "        '-fflags','+nobuffer',\n",
        "        '-flags', 'low_delay',\n",
        "        '-probesize', '32',\n",
        "        '-f', 'rawvideo',\n",
        "        '-pix_fmt', 'bgr24',\n",
        "        '-s', '960x540',\n",
        "        '-r', str(timefrate),\n",
        "        '-i', 'pipe:',\n",
        "        '-c:v', 'libx264',  # Enable encoding for lower bandwidth usage\n",
        "        '-preset', 'ultrafast',  # Fast encoding to reduce latency\n",
        "        '-tune', 'zerolatency',  # Low latency setting\n",
        "        '-g', '60',  # GOP size set to 1 to make each frame a keyframe\n",
        "        '-b:v', '3000k',  # Set bitrate to 1 Mbps\n",
        "        '-maxrate', '3000k',\n",
        "        '-bufsize', '5000k',\n",
        "        '-threads', '8',  # Enable threading\n",
        "        '-f', 'mpegts',\n",
        "        f'tcp://127.0.0.1:{local_out_frame}?listen&fifo_size=50000&overrun_nonfatal=1'\n",
        "    ]\n",
        "    timefame =1/timefrate\n",
        "    ffmpeg_encode_process = subprocess.Popen((ffmpeg_encode_command), stdin=subprocess.PIPE)\n",
        "    demo_image = create_demo_image()\n",
        "    frames_to_skip = 200  # Number of frames to skip to reduce delay\n",
        "    frame_count =0\n",
        "    wait_frame = 0\n",
        "    try:\n",
        "        while True:\n",
        "            # Get the processed array and metadata from the queue\n",
        "            if len(frames_array)>wait_frame:\n",
        "                if wait_frame<timefrate:\n",
        "                    wait_frame += 1\n",
        "                    #timefrate -=1\n",
        "\n",
        "                temp_array = frames_array[-1]#frames_array.popleft()#process_queue.get()\n",
        "                source_array = source_frame\n",
        "                is_many_face = is_manyFace\n",
        "                #framex = temp_array\n",
        "                #print(source_array,temp_array)\n",
        "                processed_array = process_frame(get_one_face(source_frame),temp_array,is_manyFace)\n",
        "                framex = processed_array\n",
        "                '''\n",
        "                if source_frame is not None: #and temp_array is not None:\n",
        "                    source_array = None\n",
        "                    temp_array = None\n",
        "                    is_many_face = None\n",
        "\n",
        "                '''\n",
        "            else:\n",
        "                framex = demo_image\n",
        "                # Write the frame to FFmpeg for encoding and streaming\n",
        "            ffmpeg_encode_process.stdin.write(framex.tobytes())\n",
        "            time.sleep(timefame)\n",
        "    finally:\n",
        "    #ffmpeg_receive_process.terminate()\n",
        "        ffmpeg_encode_process.terminate()\n",
        "# Create sockets\n",
        "pull_socket = pull_socket(local_in_source)\n",
        "# Run both workers in separate threads\n",
        "# Start the pull worker thread\n",
        "pull_thread = threading.Thread(target=pull_worker, args=(pull_socket,))\n",
        "pull_thread.start()\n",
        "# Start the push worker thread\n",
        "pull_thread_two = threading.Thread(target=pull_worker_two, args=(local_in_temp,))\n",
        "pull_thread_two.start()\n",
        "# Start the push worker thread\n",
        "push_thread = threading.Thread(target=push_worker,args=(local_out_frame,))\n",
        "push_thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYQRVPsdxizn",
        "outputId": "3e447eed-45d7-4301-8a99-fa2b9e088196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PULL one socket bound to tcp://127.0.0.1:5555\n",
            "OutputStream ffmpeg bound to tcp://127.0.0.1:5557?listen\n",
            "InputStream ffmpeg bound from tcp://127.0.0.1:5556?listen\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional] For Image Swap\n",
        "\n",
        "For image swapping run this cell.\n",
        "\n",
        "\n",
        "\n",
        "Note: You can not run both cell at same time. Either This or The cell Above (For Live Streaming)"
      ],
      "metadata": {
        "id": "Eb_cbyoaHKrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zmq\n",
        "import threading\n",
        "import cv2\n",
        "import numpy as np\n",
        "import msgpack\n",
        "import queue\n",
        "import time\n",
        "import zlib\n",
        "from tqdm import tqdm\n",
        "import subprocess\n",
        "from collections import deque\n",
        "import matplotlib as plt\n",
        "def push_socket(local_out_port):\n",
        "    context = zmq.Context()\n",
        "    socket = context.socket(zmq.REQ)\n",
        "    socket.setsockopt(zmq.SNDHWM, 100000)\n",
        "    socket.setsockopt(zmq.LINGER, 0)\n",
        "    address = f\"tcp://127.0.0.1:{local_out_port}\"\n",
        "    socket.bind(address)  # Binding to a local port\n",
        "    print(f\"PUSH socket bound to {address}\")\n",
        "    return socket\n",
        "def pull_socket(local_in_port):\n",
        "    context = zmq.Context()\n",
        "    socket = context.socket(zmq.REP)\n",
        "    socket.setsockopt(zmq.RCVHWM, 100000)\n",
        "    socket.setsockopt(zmq.LINGER, 0)\n",
        "    address = f\"tcp://127.0.0.1:{local_in_port}\"\n",
        "    socket.bind(address)  # Binding to a different local port\n",
        "    print(f\"PULL one socket bound to {address}\")\n",
        "    return socket\n",
        "# Compress image\n",
        "def compress_image(image, quality=95):\n",
        "    # Set the JPEG quality parameter\n",
        "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n",
        "    # Encode the image as a JPEG\n",
        "    result, encimg = cv2.imencode('.jpg', image, encode_param)\n",
        "    if not result:\n",
        "        raise Exception(\"Image encoding failed\")\n",
        "    # Decode the encoded image back to an image format\n",
        "    decimg = cv2.imdecode(encimg, 1)\n",
        "    return decimg\n",
        "# Decompress image\n",
        "def decompress_image(encimg):\n",
        "    image = cv2.imdecode(np.frombuffer(encimg, np.uint8), cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "# Global variables\n",
        "frames_array=deque(maxlen=2000)\n",
        "source_frame = None\n",
        "is_manyFace = None\n",
        "frameSize = '640x480'\n",
        "fps = None\n",
        "#functions\n",
        "def pull_worker(pull_socket):\n",
        "    global source_frame,is_manyFace,frameSize,fps\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive the JSON with total chunks\n",
        "            meta_data_json = pull_socket.recv_json()\n",
        "            #print(meta_data_json)\n",
        "            total_chunk = meta_data_json['total_chunk']\n",
        "            # Send acknowledgment for metadata\n",
        "            pull_socket.send_string(\"ACK\")\n",
        "            # Receive the array bytes\n",
        "            source_array_bytes =b''\n",
        "            for i in range(total_chunk):\n",
        "                chunk = pull_socket.recv()\n",
        "                source_array_bytes += chunk\n",
        "                pull_socket.send_string(f\"ACK {i + 1}/{total_chunk}\")\n",
        "            end_message = pull_socket.recv()\n",
        "            if end_message == b\"END\":\n",
        "                pull_socket.send_string(\"Final ACK\")\n",
        "            # Deserialize the bytes back to an ndarray\n",
        "            source_array = np.frombuffer(source_array_bytes, dtype=np.dtype(meta_data_json['dtype_source'])).reshape(meta_data_json['shape_source'])\n",
        "            #plt.imshow(source_array[:, :, ::-1])\n",
        "            #plt.show()\n",
        "            #frame_queue.append([\"source\", source_array])\n",
        "            source_frame = source_array\n",
        "            is_manyFace = meta_data_json['manyface']\n",
        "            frames_array.append([\"source\",source_array,is_manyFace])\n",
        "                #process_queue.put((\"source\", source_array))\n",
        "            #break\n",
        "        except zmq.Again:\n",
        "            # Sleep briefly to avoid busy-waiting\n",
        "            time.sleep(0.01)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "def pull_worker_two(pull_socket_two):\n",
        "    while True:\n",
        "        try:\n",
        "           # Receive the JSON with total chunks\n",
        "            meta_data_json = pull_socket_two.recv_json()\n",
        "            #print(meta_data_json)\n",
        "            total_chunk = meta_data_json['total_chunk']\n",
        "            # Send acknowledgment for metadata\n",
        "            pull_socket_two.send_string(\"ACK\")\n",
        "            # Receive the array bytes\n",
        "            temp_array_bytes =b''\n",
        "            for i in range(total_chunk):\n",
        "                chunk = pull_socket_two.recv()\n",
        "                temp_array_bytes += chunk\n",
        "                pull_socket_two.send_string(f\"ACK {i + 1}/{total_chunk}\")\n",
        "            end_message = pull_socket_two.recv()\n",
        "            if end_message == b\"END\":\n",
        "                pull_socket_two.send_string(\"Final ACK\")\n",
        "            # Deserialize the bytes back to an ndarray\n",
        "            temp_array = np.frombuffer(temp_array_bytes, dtype=np.dtype(meta_data_json['dtype_temp'])).reshape(meta_data_json['shape_temp'])\n",
        "            #if source_frame is not None:\n",
        "            frames_array.append([\"temp\",temp_array])\n",
        "            print(\"added\",len(frames_array))\n",
        "            #break\n",
        "        except zmq.Again:\n",
        "            # Sleep briefly to avoid busy-waiting\n",
        "            time.sleep(0.01)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "def push_worker(push_socket):\n",
        "    global source_frame,is_manyFace,frameSize,fps\n",
        "    temp_frm = None\n",
        "    source_frm = None\n",
        "    is_manyface = None\n",
        "    try:\n",
        "        while True:\n",
        "            # Get the processed array and metadata from the queue\n",
        "            if len(frames_array)>0:\n",
        "                #print(frames_array)\n",
        "                item = frames_array.popleft()#process_queue.get()\n",
        "                if item[0]==\"source\":\n",
        "                    source_frm = item[1]\n",
        "                    is_manyface = item[2]\n",
        "                if item[0]==\"temp\":\n",
        "                    temp_frm = item[1]\n",
        "                    print(\"Recieved\")\n",
        "                if temp_frm is not None and source_frm is not None:\n",
        "                    processed_frm =process_frame(get_one_face(source_frm),temp_frm,is_manyface)\n",
        "                    face_bytes = processed_frm.tobytes()\n",
        "                    chunk_size = 1024*200\n",
        "                    total_chunk = len(face_bytes) // chunk_size + 1\n",
        "                    metadata ={\n",
        "                        'dtype_source':str(processed_frm.dtype),\n",
        "                        'shape_source':processed_frm.shape,\n",
        "                        'size':'640x480',\n",
        "                        'fps':'60'\n",
        "                        #'shape_temp':temp_frame.shape\n",
        "                    }\n",
        "                    new_metadata = {'total_chunk': total_chunk}\n",
        "                    metadata.update(new_metadata)\n",
        "                    # Send metadata first\n",
        "                    push_socket.send_json(metadata)\n",
        "                    # Wait for acknowledgment for metadata\n",
        "                    ack = push_socket.recv_string()\n",
        "                    with tqdm(total=total_chunk, desc=\"Sending chunks\", unit=\"chunk\") as pbar:\n",
        "                        for i in range(total_chunk):\n",
        "                            chunk = face_bytes[i * chunk_size:(i + 1) * chunk_size]\n",
        "                            # Send the chunk\n",
        "                            push_socket.send(chunk)\n",
        "                            # Wait for acknowledgment after sending each chunk\n",
        "                            ack = push_socket.recv_string()\n",
        "                            pbar.set_postfix_str(f'Chunk {i + 1}/{total_chunk} ack: {ack}')\n",
        "                            pbar.update(1)\n",
        "                    # Send a final message to indicate all chunks are sent\n",
        "                    push_socket.send(b\"END\")\n",
        "                    # Wait for the final reply\n",
        "                    final_reply_message = push_socket.recv_string()\n",
        "                    print(f\"Received final reply: {final_reply_message}\")\n",
        "                    temp_frm = None\n",
        "                    source_frm = None\n",
        "                    is_manyface = None\n",
        "    except Exception as e:\n",
        "        print (f\"Error in Push Wokr {e}\")\n",
        "local_in_source = 5555\n",
        "local_in_temp = 5556\n",
        "local_out_frame = 5557\n",
        "# Create sockets\n",
        "pull_socket_ = pull_socket(local_in_source)\n",
        "pull_socket_two = pull_socket(local_in_temp)\n",
        "push_socket_ = push_socket(local_out_frame)\n",
        "# Run both workers in separate threads\n",
        "# Start the pull worker thread\n",
        "pull_thread = threading.Thread(target=pull_worker, args=(pull_socket_,))\n",
        "pull_thread.start()\n",
        "# Start the push worker thread\n",
        "pull_thread_two = threading.Thread(target=pull_worker_two, args=(pull_socket_two,))\n",
        "pull_thread_two.start()\n",
        "# Start the push worker thread\n",
        "push_thread = threading.Thread(target=push_worker,args=(push_socket_,))\n",
        "push_thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A_nrCfTpHWS4",
        "outputId": "51559feb-3ac2-4ab9-b434-1b4c07ad8bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PULL one socket bound to tcp://127.0.0.1:5555\n",
            "PULL one socket bound to tcp://127.0.0.1:5556\n",
            "PUSH socket bound to tcp://127.0.0.1:5557\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional]  Open FRP tunnel"
      ],
      "metadata": {
        "id": "a9JW1rhH3H-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HostIP =194.113.64.71\n",
        "frpc_config = f\"\"\"serverAddr = \"{str(HostIP)}\"\n",
        "serverPort = 7000\n",
        "[[proxies]]\n",
        "name = \"Pull-tcp\"\n",
        "type = \"tcp\"\n",
        "localIP = \"127.0.0.1\"\n",
        "localPort = {local_in_source}\n",
        "remotePort = 6000\n",
        "[[proxies]]\n",
        "name = \"Pull-tcp_two\"\n",
        "type = \"tcp\"\n",
        "localIP = \"127.0.0.1\"\n",
        "localPort = {local_in_temp}\n",
        "remotePort = 6001\n",
        "[[proxies]]\n",
        "name = \"Push-tcp\"\n",
        "type = \"tcp\"\n",
        "localIP = \"127.0.0.1\"\n",
        "localPort = {local_out_frame}\n",
        "remotePort = 6002\"\"\"\n",
        "with open('frp_0.59.0_linux_amd64/frpc.toml', 'w') as f:\n",
        "    f.write(frpc_config)\n",
        "#Remote tcp\n",
        "print(f'tcp://{str(HostIP)}:6000 ---> {local_in_source}')\n",
        "print(f'tcp://{str(HostIP)}:6001 ---> {local_in_temp}')\n",
        "print(f'tcp://1{str(HostIP)}:6002 ---> {local_out_frame}')\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import time\n",
        "ps = Popen('/kaggle/working/deepfakecollab/Scripts/open_tunnel_frs.sh', stdout=PIPE, stderr=PIPE)\n",
        "time.sleep(3)\n",
        "!/kaggle/working/deepfakecollab/Scripts/open_tunnel_frs.sh"
      ],
      "metadata": {
        "id": "VNDmeHcx3Zrx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ee78d229-ddae-4778-d84f-5e50325c7df1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-77049e4f6072>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-77049e4f6072>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    HostIP =194.113.64.71\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional]  Open Ngrok tunnel"
      ],
      "metadata": {
        "id": "buCnH_YpxKWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import json\n",
        "import time\n",
        "def run_with_pipe(command):\n",
        "  commands = list(map(shlex.split,command.split(\"|\")))\n",
        "  ps = Popen(commands[0], stdout=PIPE, stderr=PIPE)\n",
        "  for command in commands[1:]:\n",
        "    ps = Popen(command, stdin=ps.stdout, stdout=PIPE, stderr=PIPE)\n",
        "  return ps.stdout.readlines()\n",
        "def get_tunnel_adresses():\n",
        "  info = run_with_pipe(\"curl http://localhost:4040/api/tunnels\")\n",
        "  assert info\n",
        "  info = json.loads(info[0])\n",
        "  for tunnel in info['tunnels']:\n",
        "    url = tunnel['public_url']\n",
        "    port = url.split(':')[-1]\n",
        "    local_port = tunnel['config']['addr'].split(':')[-1]\n",
        "    print(f'{url} -> {local_port} [{tunnel[\"name\"]}]')\n",
        "    if tunnel['name'] == 'input':\n",
        "      in_addr = url\n",
        "    elif tunnel['name'] == 'inputtwo':\n",
        "      in_addrtwo = url\n",
        "    elif tunnel['name'] == 'output':\n",
        "      out_addr = url\n",
        "    else:\n",
        "      print(f'unknown tunnel: {tunnel[\"name\"]}')\n",
        "  return in_addr,in_addrtwo, out_addr\n",
        "config =\\\n",
        "f\"\"\"\n",
        "version: 2\n",
        "authtoken: {authtoken}\n",
        "region: {region}\n",
        "console_ui: False\n",
        "tunnels:\n",
        "  input:\n",
        "    addr: {local_in_source}\n",
        "    proto: tcp\n",
        "  inputtwo:\n",
        "    addr: {local_in_temp}\n",
        "    proto: tcp\n",
        "  output:\n",
        "    addr: {local_out_frame}\n",
        "    proto: tcp\n",
        "\"\"\"\n",
        "with open('ngrok.conf', 'w') as f:\n",
        "  f.write(config)\n",
        "# (Re)Open tunnel\n",
        "ps = Popen('/content/deepfakecollab/Scripts/open_tunnel_ngrok.sh', stdout=PIPE, stderr=PIPE)\n",
        "time.sleep(3)\n",
        "# Get tunnel addresses\n",
        "try:\n",
        "  in_addr,in_addr_two, out_addr = get_tunnel_adresses()\n",
        "  print(\"Tunnel opened\")\n",
        "except Exception as e:\n",
        "  [print(l.decode(), end='') for l in ps.stdout.readlines()]\n",
        "  print(\"Something went wrong, reopen the tunnel\")"
      ],
      "metadata": {
        "id": "HyY2B5bmxlui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "0445a47c-6544-4329-c04b-e051675f04d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'authtoken' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b339596d9548>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m f\"\"\"\n\u001b[1;32m     31\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mauthtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mauthtoken\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mconsole_ui\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'authtoken' is not defined"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **KILL PROCESS (PORTS)**"
      ],
      "metadata": {
        "id": "ISPEVhDV3x3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "# List of ports to free\n",
        "ports = [5555, 5556, 5557]\n",
        "for port in ports:\n",
        "    # Find the process ID (PID) using the port\n",
        "    result = subprocess.run(f\"lsof -t -i:{port}\", shell=True, capture_output=True, text=True)\n",
        "    pid = result.stdout.strip()\n",
        "\n",
        "    # Kill the process if it exists\n",
        "    if pid:\n",
        "        subprocess.run(f\"kill -9 {pid}\", shell=True)\n",
        "        print(f\"Terminated process on port {port} with PID {pid}\")\n",
        "    else:\n",
        "        print(f\"No process found on port {port}\")\n"
      ],
      "metadata": {
        "id": "4kC3axJEx5e8"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}